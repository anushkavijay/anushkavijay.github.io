{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/anushkavijay/anushkavijay.github.io/blob/main/rnn_ml_model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-E5r0GYs1NyX",
        "outputId": "1fda5571-48f0-4259-f128-36456c9258c4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jNzkMounzeF2"
      },
      "outputs": [],
      "source": [
        "import gzip\n",
        "import pickle\n",
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader, Dataset, random_split\n",
        "from torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence\n",
        "import numpy as np\n",
        "import os\n",
        "import gc"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a7MYPiI2zfFo"
      },
      "outputs": [],
      "source": [
        "class SortingDataset(Dataset):\n",
        "    def __init__(self, data, labels):\n",
        "        self.data = data\n",
        "        self.labels = labels\n",
        "        self.lengths = [len(seq) for seq in data]  # Store lengths of sequences\n",
        "        self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        sample = torch.tensor(self.data[idx], dtype=torch.float32).contiguous()\n",
        "        label = torch.tensor(self.labels[idx], dtype=torch.long).contiguous()\n",
        "        length = self.lengths[idx]  # Length of the sequence\n",
        "        return sample, label, length"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dz-8kT9OzhGj"
      },
      "outputs": [],
      "source": [
        "class SortingLSTM(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, num_layers, num_classes):\n",
        "        super(SortingLSTM, self).__init__()\n",
        "        self.hidden_size = hidden_size\n",
        "        self.num_layers = num_layers\n",
        "        self.lstm = nn.LSTM(input_size, hidden_size, num_layers, batch_first = True)\n",
        "        self.fc = nn.Linear(hidden_size, num_classes)\n",
        "        self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "    def forward(self, x, lengths):\n",
        "        # Pack the padded sequence\n",
        "        # packed_input = pack_padded_sequence(x.contiguous(), lengths, batch_first=True, enforce_sorted=False).to(self.device)\n",
        "        # print(\"FORWAAAARD\")\n",
        "        if torch.isnan(x).any() or torch.isinf(x).any():\n",
        "          print(\"Input tensor contains NaNs or Infs!\")\n",
        "\n",
        "        # print(f\"input: {x}\")\n",
        "        packed_input = pack_padded_sequence(x, lengths.cpu(), batch_first=True, enforce_sorted=False).to(self.device)         # Initialize hidden state and cell state\n",
        "        # print(x.size())\n",
        "        h0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(self.device).contiguous()\n",
        "        c0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(self.device).contiguous()\n",
        "\n",
        "        # Forward pass through LSTM\n",
        "        # print(\"is c0 contiguous\")\n",
        "        # print(c0.is_contiguous())\n",
        "        packed_output, _ = self.lstm(packed_input, (h0, c0))\n",
        "        output, _ = pad_packed_sequence(packed_output, batch_first=True)\n",
        "        output = output.to(self.device) # move the unpacked output to the correct device\n",
        "\n",
        "\n",
        "        # Use the output of the last valid time step for each sequence\n",
        "        out = output[torch.arange(output.size(0)), lengths - 1] # use unpacked output to access hidden state\n",
        "\n",
        "        # Fully connected layer\n",
        "        out = self.fc(out)\n",
        "        return out"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zzfgtxXa1DYm"
      },
      "outputs": [],
      "source": [
        "def collate_fn(batch):\n",
        "    # Separate sequences, labels, and lengths\n",
        "    sequences, labels, lengths = zip(*batch)\n",
        "\n",
        "    # Pad sequences to the maximum length in the batch\n",
        "    padded_sequences = torch.nn.utils.rnn.pad_sequence(sequences, batch_first=True)\n",
        "\n",
        "    # Stack labels and lengths\n",
        "    labels = torch.stack(labels)\n",
        "    lengths = torch.tensor(lengths)\n",
        "\n",
        "    return padded_sequences, labels, lengths\n",
        "\n",
        "def read_array(file_path):\n",
        "    with gzip.open(file_path, 'rb') as f:\n",
        "        array = pickle.loads(f.read())\n",
        "    return array"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MHwPrUFc6leh"
      },
      "outputs": [],
      "source": [
        "def get_data():\n",
        "  input_data = []\n",
        "  input_data += read_array('/content/drive/My Drive/CS/CS 263/cs263_ml/data/small_uniform_arrays.gz')\n",
        "  input_data += read_array('/content/drive/My Drive/CS/CS 263/cs263_ml/data/small_poisson_arrays.gz')\n",
        "  input_data += read_array('/content/drive/My Drive/CS/CS 263/cs263_ml/data/small_normal_arrays.gz')\n",
        "  input_data += read_array('/content/drive/My Drive/CS/CS 263/cs263_ml/data/small_reverse_arrays.gz')\n",
        "  input_data += read_array('/content/drive/My Drive/CS/CS 263/cs263_ml/data/small_nearly_sorted_arrays.gz')\n",
        "  return input_data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QOWDAseX6pBL"
      },
      "outputs": [],
      "source": [
        "# data = read_array('/content/drive/My Drive/CS/CS 263/cs263_ml/data/uniform_arrays.gz')\n",
        "# input_data = []\n",
        "# indices = []\n",
        "# for i,el in enumerate(data):\n",
        "#   if len(el) < 10000:\n",
        "#     input_data.append(el)\n",
        "#     indices.append(i)\n",
        "\n",
        "input_data = get_data()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('/content/drive/My Drive/CS/CS 263/cs263_ml/data/small_training_runtime_only_data.csv')\n",
        "total_labels = df['Best Algorithm'].to_numpy()"
      ],
      "metadata": {
        "id": "R0XSHKlgCq19"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "WNxpa8c89hsH",
        "outputId": "4cda2f41-fee4-465b-960e-59248572ad4b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "25000\n",
            "25000\n"
          ]
        }
      ],
      "source": [
        "print(len(total_labels))\n",
        "print(len(input_data))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p82pKD826t2S"
      },
      "outputs": [],
      "source": [
        "# Create dataset and dataloader\n",
        "\n",
        "train_ratio = 0.8\n",
        "test_ratio = 0.1\n",
        "validation_ratio = 0.1\n",
        "\n",
        "dataset = SortingDataset(input_data, total_labels)\n",
        "\n",
        "# split input data and labels\n",
        "train_size = int(train_ratio*len(dataset))\n",
        "val_size = int(validation_ratio*len(dataset))\n",
        "test_size = int(test_ratio*len(dataset))\n",
        "\n",
        "train_dataset, val_dataset, test_dataset = random_split(dataset, [train_size, val_size, test_size])\n",
        "\n",
        "# Create dataset and dataloader\n",
        "batch_size = 200\n",
        "train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, collate_fn=collate_fn)\n",
        "val_dataloader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, collate_fn=collate_fn)\n",
        "test_dataloader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, collate_fn=collate_fn)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Rw-bwoEazmGC"
      },
      "outputs": [],
      "source": [
        "# Hyperparameters\n",
        "os.environ['CUDA_LAUNCH_BLOCKING']=\"1\"\n",
        "os.environ['TORCH_USE_CUDA_DSA'] = \"1\"\n",
        "input_size = 1  # Since each element in the array is a single integer\n",
        "hidden_size = 64\n",
        "num_layers = 2\n",
        "num_classes = 4\n",
        "learning_rate = 0.001\n",
        "num_epochs = 5\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "# Initialize the model\n",
        "model = SortingLSTM(input_size, hidden_size, num_layers, num_classes).to(device)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Loss and optimizer\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.02)"
      ],
      "metadata": {
        "id": "3Xx8_6KTYjC5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oRisHhIYzoT_",
        "outputId": "0bf570a3-8ee7-4ea2-d3f1-748333842bc9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0\n",
            "Epoch [1/5], Train Loss: 0.6411, Validation Loss: 0.5190\n"
          ]
        }
      ],
      "source": [
        "counter = 0\n",
        "model.train()\n",
        "for epoch in range(1):\n",
        "    for sequences, labels, lengths in train_dataloader:\n",
        "        # Forward pass\n",
        "        sequences = sequences.to(device)\n",
        "        lengths = lengths.to(device)\n",
        "        outputs = model(sequences.unsqueeze(-1), lengths).to(device)\n",
        "        labels = labels.to(device)\n",
        "        # print(f\"size: outputs: {len(outputs)}, labels: {len(labels)}\")\n",
        "        # print(\"testing target: \")\n",
        "        # print(\"outputs: \", outputs)\n",
        "        # print(\"labels: \", labels)\n",
        "        loss = criterion(outputs, labels)\n",
        "        if counter % 100 == 0:\n",
        "          print(counter)\n",
        "        counter += 1\n",
        "\n",
        "        # Backward and optimize\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "    with torch.no_grad():\n",
        "      for sequences, labels, lengths in val_dataloader:\n",
        "          outputs = model(sequences.unsqueeze(-1), lengths).to(device)\n",
        "          labels = labels.to(device)\n",
        "          val_loss = criterion(outputs, labels)\n",
        "\n",
        "    print(f'Epoch [{epoch+1}/{num_epochs}], Train Loss: {loss.item():.4f}, Validation Loss: {val_loss.item():.4f}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7FPgVA84zrCM",
        "outputId": "c59cbc80-69d6-4d10-ceee-511049e5831d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Accuracy: 74.84%\n"
          ]
        }
      ],
      "source": [
        "# Test the model\n",
        "\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    for sequences, labels, lengths in test_dataloader:\n",
        "        labels = labels.to(device)\n",
        "        outputs = model(sequences.unsqueeze(-1), lengths).to(device)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "    print(f'Test Accuracy: {100 * correct / total:.2f}%')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.save(model.state_dict(), '/content/drive/My Drive/CS/CS 263/cs263_ml/data/rnn_runtime_only.pt')"
      ],
      "metadata": {
        "id": "9NO7YRd_JKzt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "r0IiuPpOIX6e"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}